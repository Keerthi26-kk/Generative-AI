{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074a65da-970d-4def-bd10-83fc46d24224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffdc2e73-8a26-4193-958e-dffc507cedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00bd440a-c4fb-4f09-82e5-2910b01d1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19adf5b7-1897-4cf9-b3d7-b1a54219c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998fecca-2f58-458a-9dcd-ada80d3444a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecee0aa-9ccb-4170-83ef-5a9ff66f065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f98ff21-9f0d-4700-abde-15b2da572f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7f10a54-56b1-41cb-8c9e-92600be57ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "656c6bae-0a86-4423-8c4d-c65afba478d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a45b777a-29ef-44d2-ba67-a8d99712a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "    \n",
    "    categorical_cols = ['Customer demographics','Product type']\n",
    "    #for col in categorical_cols:\n",
    "        #if col in df.columns:\n",
    "          #  df[col].fillna('Unkown',inplace=True)\n",
    "    print(\"Availability unique:\", df['Availability'].unique())\n",
    "    print(\"Stock levels min:\", df['Stock levels'].min())\n",
    "    print(\"Lead times median:\", df['Lead times'].median())\n",
    "    print(\"Lead times sample values:\", df['Lead times'].sample(5))\n",
    "\n",
    "        \n",
    "    \n",
    "    if 'Availability' in df.columns and 'Stock levels' in df.columns and 'Lead times' in df.columns:\n",
    "        df['disruption'] = ((df['Availability'] <20) & \n",
    "                            (df['Stock levels'] < 20) & \n",
    "                            (df['Lead times'] > df['Lead times'].median())).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Required columns for target generation are missing.\")\n",
    "\n",
    "    \n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    bool_cols = df.select_dtypes(include='bool').columns\n",
    "    df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5778c3e4-ea35-4df4-a1df-2d593dd07ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def load_and_preprocess_data(file_path):\\n    df=pd.read_csv(file_path)\\n    df.fillna(df.median(),inplace=True)\\n    df['Customer demographics'].fillna('Unknown',inplace=True)\\n    df['disruption']= ((df['Availability']==0)&\\n                       (df['Stock levels']<20)&\\n                       (df['Lead times']>df['Lead times'].median())).astype(int)\\n    df=pd.get_dummies(df,columns =['Product type','SKU','Cusomer demographics'],drop_first=True)\\n    return df\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def load_and_preprocess_data(file_path):\n",
    "    df=pd.read_csv(file_path)\n",
    "    df.fillna(df.median(),inplace=True)\n",
    "    df['Customer demographics'].fillna('Unknown',inplace=True)\n",
    "    df['disruption']= ((df['Availability']==0)&\n",
    "                       (df['Stock levels']<20)&\n",
    "                       (df['Lead times']>df['Lead times'].median())).astype(int)\n",
    "    df=pd.get_dummies(df,columns =['Product type','SKU','Cusomer demographics'],drop_first=True)\n",
    "    return df\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8bcad368-94d6-4fbb-9920-f17ae7fc7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train,Y_train):\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    Y_train = Y_train.astype(int)\n",
    "    print(\"Train:\", Y_train.value_counts())\n",
    "    \n",
    "    #print(\"Y_train distribution:\\n\", Y_train.value_counts())\n",
    "\n",
    "    print(np.unique(Y_train))\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective = 'binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=100,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        base_score=0.5\n",
    "    \n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'max_depth':[3,5,7],\n",
    "        'learning_rate':[0.01,0.05,0.1],\n",
    "        'n_estimators':[100,200],\n",
    "        'subsample':[0.8,1.0],\n",
    "        'colsample_bytree':[0.8,1.0]\n",
    "    }\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        scoring='accuracy',\n",
    "        error_score='raise'\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train,Y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2b27bd7b-be24-42e7-a9df-188d726b13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X_test,Y_test):\n",
    "    y_pred =model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "    print(\"Test:\", Y_test.value_counts())\n",
    "\n",
    "    cm = confusion_matrix(Y_test,y_pred)\n",
    "    print(\"Confusion Matrix :\")\n",
    "    print(cm)\n",
    "\n",
    "    print(\"\\n Classification Report :\")\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_test,y_pred_prob)\n",
    "    print(f\"\\n ROC AUC Score:{roc_auc:.4f}\")\n",
    "\n",
    "    return cm,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fc3817d6-ff5c-4b1e-b257-ab7fcd963cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model):\n",
    "    xgb.plot_importance(model,importance_type='weight')\n",
    "    plt.title(\"Feature Importance for Supply Chain Disruption Prediction\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    importance = model.get_booster().get_score(importance_type='weight')\n",
    "    if not importance:\n",
    "        print(\"Still no importance found â€” check data quality again.\")\n",
    "    else:\n",
    "        print(\"Feature importances:\", importance)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e4c53ea6-6aaa-40b7-a1ce-cbb95664f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_path):\n",
    "    df = load_and_preprocess_data(file_path)\n",
    "    #print(df.dtypes)\n",
    "   # print(df.isnull().sum())\n",
    "    print(\"Target value counts:\\n\", df['disruption'].value_counts())\n",
    "    \n",
    "    feature_cols = [col for col in df.columns if col not in['disruption']]\n",
    "\n",
    "    x=df[feature_cols]\n",
    "    y=df['disruption']\n",
    "    assert all(np.issubdtype(x[col].dtype, np.number) for col in x.columns), \"Non-numeric data found!\"\n",
    "    print(\"Unique values in target:\", np.unique(y))\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
    "    scaler= StandardScaler()\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=x.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns=x.columns)\n",
    "\n",
    "    model=train_model(X_train,Y_train)\n",
    "\n",
    "    cm,roc_auc =evaluate_model(model,X_test,Y_test)\n",
    "\n",
    "    plot_feature_importance(model)\n",
    "\n",
    "    return model,cm,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "441ccfa6-e83a-4752-9032-41986896ea76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Availability unique: [ 55  95  34  68  26  87  48  59  78  35  11  41   5  94  74  82  23 100\n",
      "  22  60  30  32  73   9  42  12   3  10  28  43  63  96  75  97  98   6\n",
      "   1  93  19  91  61  16  90  65  81  89  72  52  29  62  14  88  64  50\n",
      "  56  13  99  83  18  24  58  44  17]\n",
      "Stock levels min: 0\n",
      "Lead times median: 17.0\n",
      "Lead times sample values: 35    27\n",
      "79    25\n",
      "33    17\n",
      "37     8\n",
      "25    11\n",
      "Name: Lead times, dtype: int64\n",
      "Target value counts:\n",
      " disruption\n",
      "0    100\n",
      "Name: count, dtype: int64\n",
      "Unique values in target: [0]\n",
      "Train: disruption\n",
      "0    80\n",
      "Name: count, dtype: int64\n",
      "[0]\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Test: disruption\n",
      "0    20\n",
      "Name: count, dtype: int64\n",
      "Confusion Matrix :\n",
      "[[20]]\n",
      "\n",
      " Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "\n",
      " ROC AUC Score:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Booster.get_score() results in empty.  This maybe caused by having all trees as decision dumps.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[181], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      2\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/keerthika/Downloads/suply_chain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     model,cm,roc_auc\u001b[38;5;241m=\u001b[39m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Trained and Executed Successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[179], line 22\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m=\u001b[39mtrain_model(X_train,Y_train)\n\u001b[1;32m     20\u001b[0m cm,roc_auc \u001b[38;5;241m=\u001b[39mevaluate_model(model,X_test,Y_test)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mplot_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model,cm,roc_auc\n",
      "Cell \u001b[0;32mIn[173], line 2\u001b[0m, in \u001b[0;36mplot_feature_importance\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_feature_importance\u001b[39m(model):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimportance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Importance for Supply Chain Disruption Prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/xgboost/plotting.py:102\u001b[0m, in \u001b[0;36mplot_importance\u001b[0;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, values_format, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree must be Booster, XGBModel or dict instance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m importance:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBooster.get_score() results in empty.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis maybe caused by having all trees as decision dumps.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    107\u001b[0m tuples \u001b[38;5;241m=\u001b[39m [(k, importance[k]) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m importance]\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_num_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# pylint: disable=invalid-unary-operand-type\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Booster.get_score() results in empty.  This maybe caused by having all trees as decision dumps."
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    file_path = '/Users/keerthika/Downloads/suply_chain.csv'\n",
    "    model,cm,roc_auc=main(file_path)\n",
    "\n",
    "    print(\"Model Trained and Executed Successfully\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d7c7a-b1c1-4ab8-92a9-0c40dd6cbd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9aaae8-4ae9-4b24-a6e2-5540bbe793f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
